#!/usr/bin/Rscript

packages <- c("caret", "lubridate", "xlsx", "rJava","doSNOW", "reshape", "randomForest",
              "foreach","doParallel","gbm","openxlsx","teradataR","RODBC","digest","sendmailR")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}
#### IMPORTANT NOTE
#### Filepaths will likely have to be specified depending on
#### where this program is run. The filepaths below may need
#### to be checked
library(caret)
library(doParallel)
library(xlsx)
library(sendmailR)
from <- "<samuel.tisi@walmart.com>"
to <- "<Zhe.Li@walmart.ca>"
subject <- "Walmart Preditive Modelling has begun"
body<-("Model has began to run ")
mailControl=list(smtpServer="smtp-gw1.wal-mart.com")
#sendmail(from=from,to=to,subject=subject,msg=body,control=mailControl)
#source('//cants802/share2/SHARE/Paul Rizk/Useful Files/Functions List.R')
setwd("//cants802/share2/SHARE/Logistics Analytics/Forecast")
getSystem = function(){return(Sys.info()['sysname'])}

print("Beginning program")

####################################
### Function Definitions Section ###
####################################

# These functions compartmentalize additional read in and formats from
# other sources that were tried. Some are used within the readInFormat1 function. 
# Only readInFormat7088 and readInFormat6064_6081 are used by default in
# the final program.

# Note: These are actually called in the readInFormat() function, so look there to understand context

readInFormat7088 = function(file = "//cants802/share2/SHARE/Logistics Analytics/Forecast/Data/PDC7087and6080/Forecast (2).xls"){
  data = xlsx::read.xlsx2(file = file, sheetIndex = 3, colIndex = 1:3, colClasses = c('Date','numeric','numeric'))
  names(data) = c('date','SSTK','PBYL')
  data = reshape2::melt(data, id.vars = 'date')
  data$dc = 7088
  names(data)[names(data) %in% c('variable','value')] = c('channel','volume')
  data = data[,c('date','dc','channel','volume')]
  data = data[complete.cases(data),]
  return(data)
}

readInFormat6064_6081 = function(file = "//cants802/share2/SHARE/Logistics Analytics/Forecast/Data/PDC7087and6080/6081 Forecast.xls"){
  data = xlsx::read.xlsx2(file = file, sheetIndex = 3, colIndex = 1:2, colClasses = c('Date','numeric','numeric'))
  names(data) = c('date','SSTK')
  data = reshape2::melt(data, id.vars = 'date')
  data$dc = 6081
  names(data)[names(data) %in% c('variable','value')] = c('channel','volume')
  data = data[,c('date','dc','channel','volume')]
  data = data[complete.cases(data),]
  return(data)
}

# This function is used to read in the main data source from an xlsx file
# located in \\cadfs\\logistics. The file contains dates, channels, dcs and case volumes
# as reported to CA Logistics every morning through email. The file is updated manually
# by Paula or Val. Most of this function involves trimming this file down to
# the bare necessities as well as some formatting

readInFormat1 = function(filename = "//cadfs/logistics/Logistics/PDC Forecast/Forecasting/Forecast VS. Actual 2014 - New 2014 val.xlsm", 
                         clip6601 = T, 
                         remove6064 = T, 
                         includePredictions = F, 
                         replace7088 = T, 
                         replace6081 = T)
{
  if(includePredictions){
    data1 = xlsx::read.xlsx2(filename, sheetIndex = 2, colIndex = c(1:5), colClasses = c('Date','character','character','numeric','numeric'))
  }
  else{
    data1 = xlsx::read.xlsx2(filename, sheetIndex = 2, colIndex = c(1:3,5), colClasses = c('Date','character','character','numeric'))    
  }
  names(data1) = tolower(names(data1))
  names(data1)[names(data1)=="actual...appt.log"] = "volume"
  data1 = data1[data1$channel != 'PBYL' | data1$dc != 6081,]
  data1 = subset(data1, subset = lubridate::year(data1$date) != 2005)
  data1$date[data1$date == "2105-04-12"] = as.Date('2015/4/12')
  data1$dc = as.character(data1$dc)
  data1 = data1[!duplicated(data1),]
  if(clip6601){
    data1 = data1[data1$dc != 6601 | data1$channel != 'PBYL' | as.Date(data1$date, format = '%Y-%m-%d') > as.Date("2013-11-13", format = '%Y-%m-%d'),]
  }
  if(remove6064){
    data1 = subset(data1, dc != 6064)
  }
  if(replace7088 & !includePredictions){
    add = readInFormat7088()
    data1 = merge(data1, add, c('date','dc','channel'), all = T)
    data1$volume.x[data1$dc == 7088 & is.na(data1$volume.x)] = data1$volume.y[data1$dc == 7088 & is.na(data1$volume.x)] 
    data1$volume.y = NULL
    names(data1)[names(data1) == 'volume.x'] = 'volume'
  }
  if(replace7088 & includePredictions){
    data1 = merge(data1, readInFormat7088(), by = c('date','dc','channel'), all = T)
    data1$volume.x[data1$dc == 7088] = data1$volume.y[data1$dc == 7088]
    data1$volume.y = NULL
    names(data1)[names(data1) == 'volume.x'] = 'volume'
    data1$forecast = round(data1$forecast)
    data1$volume = round(data1$volume)
  }
  if(replace6081 & !includePredictions){
    add = readInFormat6064_6081()
    data1 = merge(data1, add, c('date','dc','channel'), all = T)
    data1$volume.x[data1$dc == 6081 & is.na(data1$volume.x)] = data1$volume.y[data1$dc == 6081 & is.na(data1$volume.x)] 
    data1$volume.y = NULL
    names(data1)[names(data1) == 'volume.x'] = 'volume'
  }
  if(replace6081 & includePredictions){
    data1 = merge(data1, readInFormat6081(), by = c('date','dc','channel'), all = T)
    data1$volume.x[data1$dc == 6081] = data1$volume.y[data1$dc == 6081]
    data1$volume.y = NULL
    names(data1)[names(data1) == 'volume.x'] = 'volume'
    data1$forecast = round(data1$forecast)
    data1$volume = round(data1$volume)
  }
  data1 = data1[order(data1$dc, data1$channel, data1$date),]
  return(data1)
}



## These functions are just for feature generation

## This merges the DC-store alignments data set "alignments" with the main data set
addVariables_alignments = function(data){
  data = merge(data, alignments, by = c('date','dc'), all.x = T)
  return(data)
}  

## This just adds a bunch of date-based features (i.e. weekday, day of month etc)
addVariables_dateBased = function(data)
{ 
  data$yearDay = lubridate::yday(data$date)
  data$monthDay = lubridate::mday(data$date)
  data$weekDay = lubridate::wday(data$date)
  data$weekDaySin1 = sin(data$weekDay * 2 * pi / 7)
  data$weekDayCos1 = cos(data$weekDay * 2 * pi / 7)
  data$yearWeek = lubridate::week(data$date)
  return(data)
}

## This adds a feature that is the number of days to the nearest holiday.
## Note this could be days past or until the nearest holiday
## Needs to be updated with 2016 values *****
addVariables_proximity = function(data){
  
  # List of Ontario statuatory holidays from 2012 to 2015
  statHolidays = c('january 2 2012','february 20 2012','april 6 2012','may 21 2012','july 2 2012','september 3 2012',
                   'october 8 2012','december 25 2012','december 26 2012','august 6 2012','january 1 2013','february 16 2013',
                   'march 29 2013','may 20 2013','july 1 2013','september 2 2013','october 14 2013', 'december 25 2013',
                   'december 26 2013','august 5 2013','january 1 2014','february 17 2014','april 18 2014','may 19 2014',
                   'july 1 2014','august 4 2014','september 1 2014','october 13 2014','december 25 2014','december 26 2014',
                   'january 1 2015','february 16 2015','april 3 2015','may 18 2015','july 1 2015','august 3 2015',
                   'september 7 2015','october 12 2015','december 25 2015','december 26 2015','january 1 2016','february 15 2016',
                   'march 25 2016','may 23 2016','july 1 2016','august 1 2016','september 5 2016',
                   'october 10 2016','december 25 2016','december 26 2016'
  )
  statHolidays = strptime(statHolidays, format = '%b %d %Y')
  
  data$proximity = NA
  
  for(i in 1:nrow(data)){
    proximities = difftime(data$date[i], statHolidays,units = "days")
    data$proximity[i] = as.numeric(proximities[which(abs(proximities) == min(abs(proximities)))][1])
  }
  return(data)
}

# Simple missing value imputation by local polynomial smoother
imputeMissing = function(object){
  loess = loess(object$volume ~ as.numeric(object$date))
  missing = which(is.na(object$volume))
  if(length(missing) != 0){
    object$volume[missing] = round(predict(loess, newdata = object)[missing])
  }
  return(object)
}

# This function gets predictions from two models and averages them
getPreds = function(data, model1, model2){
  pred1 = predict(model1, newdata = data)
  pred2 = predict(model2, newdata = data)
  pred = rowMeans(cbind(pred1, pred2), na.rm = T)
  return(pred)
}


# Function for easy recoding of multiple values
recode1 = function(x, start, end, else.case = c('missing','original')) 
{
  # Set code for intentional conversion to NA
  end[is.na(end)] = 'MISSING'
  out = as.vector(end[match(x,start)])
  if(else.case[1]=='missing'){out = out; out[out=='MISSING'] = NA}
  else if(else.case[1]=='original'){out[is.na(out)]=x[is.na(out)]; out[out=='MISSING'] = NA}
  else {out[is.na(out)]=else.case[1]; out[out=='MISSING'] = NA}
  return(out)
}

# Function to extract Walmart, fiscal-calendar elements from a date
# Depends on the modified calendar file loaded below located in the project
# folder "Data" directory

load("./Data/wmCalendar")

toWalmart = function(date, to = 'day'){
  if(to %in% c('week', 'dayWeek', 'quarter','dayQuarter','year','dayYear','wm_yr_wk') == 0){
    stop("'to' arguement must be one of 'dayWeek','week','quarter','dayQuarter','year', 'dayYear' or 'wm_yr_wk'")
  }
  if(to == 'dayWeek'){
    return(as.numeric(recode1(date, wmCalendar$date, wmCalendar$day_of_wk)))
  }
  else if(to == 'week'){
    return(as.numeric(recode1(date, wmCalendar$date, wmCalendar$wm_week)))
  }
  else if(to == 'quarter'){
    return(as.numeric(recode1(date, wmCalendar$date, wmCalendar$wm_qtr)))
  }
  else if(to == 'dayQuarter'){
    return(as.numeric(recode1(date, wmCalendar$date, wmCalendar$fiscal_dayQuarter)))
  }
  else if(to == 'year'){
    return(as.numeric(recode1(date, wmCalendar$date, wmCalendar$fiscal_year)))
  }
  else if(to == 'dayYear'){
    return(as.numeric(recode1(date, wmCalendar$date, wmCalendar$fiscal_day)))
  }
  else if(to == 'wm_yr_wk'){
    return(as.numeric(recode1(date, wmCalendar$date, gsub(',','',wmCalendar$wm_yr_wk))))
  }
}



#############################################
### Preamble: Getting DC-Store Alignments ###
#############################################

# This section will pull the WHSE_ALIGN table from Teradata.
# The table gives information on current and historic DC-store alignments 
# for different item groups (alignment types). This is converted to counts
# of the number of stores serviced by each DC for each of the item groups
# (alignment types). These counts are used as features to fit the models.

# Connect to and query teraalignments WHSE_ALIGN table to get DC-store alignments
# Note: Will need to change Teradata login info on the next line
library(RODBC)
library("digest")
source("./Data/crypt.R")
load("//cants5010/Logistics/Logistics Analytics/key.RData")
credentials <- read.aes(filename = "./Data/credentials.txt",key = key)
ocn <- odbcConnect("alignment", uid = credentials[1,1], pwd = credentials[1,2])
alignments <- sqlFetch(ocn, "WHSE_ALIGN")
write.csv(alignments, file = paste('./Output/alignment', as.Date(base::date(),''),'.csv',sep=''), row.names = F)


# Format whse_align 
names(alignments) = tolower(names(alignments))

alignments$align_date = as.Date(alignments$align_date, format = '%Y-%m-%d')
alignments$expire_date = as.Date(alignments$expire_date, format = '%Y-%m-%d')
alignments$division_nbr = NULL
alignments$store_nbr = NULL

alignments = alignments[order(alignments$whse_nbr, alignments$align_date),]

# Setting up a range of dates as a template and replacing any alignment dates prior
# to this with the minimum date
dates = seq.Date(from = as.Date('2001/1/30'), to = max(alignments$expire_date[alignments$expire_date!='2500-01-01']), by = 1)
alignments$align_date[alignments$align_date < as.Date('2001/1/30')] = as.Date('2001/1/30')

names(alignments) = c('dc','align','type','expire')

# This will go through each DC-alignment type combination and count the number 
# of stores that have that DC-alignment type combination for each day 

alignments = split(alignments, interaction(alignments$dc, alignments$type, drop = T))
alignments = lapply(alignments, function(i) {
  i = reshape2::melt(i, measure.vars = c('align','expire'))
  names(i)[names(i)=='value'] = 'date'
  i$number = as.numeric(ifelse(i$variable == 'align', 1, -1))
  i = reshape2::dcast(i, dc + type + date ~ ., fun.aggregate = sum, value.var = 'number')
  names(i) = c('dc','type','date','count')
  i$date = as.Date(i$date, '%Y-%m-%d')
  return(i)
})

alignments = lapply(seq_along(alignments), function(i) {
  splits = strsplit(names(alignments)[i], '\\.')
  i = merge(data.frame(date = dates), alignments[[i]], by = 'date', all.x = T)
  i$dc = splits[[1]][1]
  i$type = splits[[1]][2]
  i$count[is.na(i$count)] = 0
  i$alignments = cumsum(i$count)
  i$count = NULL
  i = subset(i, date >= as.Date('2010/2/1') & date <= as.Date('2018/2/1'))
  return(i)
})

alignments = do.call(rbind, alignments)
alignments = reshape2::dcast(alignments, date + dc ~ type, fun.aggregate = sum, value.var = 'alignments')
alignments = alignments[order(alignments$dc, alignments$date),]

# Also calculate a total column (i.e. number of stores a DC is aligned to for any alignment type
# on a given day)
alignments$total = rowSums(subset(alignments, select = -c(date,dc)))

# This bit makes some rough historic adjustments for DCs 6064P and 6081
# 6081 alignments are 6064 (not 6064P) alignments for SSTK prior to May 2015
# 6064P alignments can't be separated out from 6064 alignments because whoever 
# created the Teraalignments table obviously didn't think that was important
alignments6064 = alignments[alignments$dc == 6064,]
alignments6081 = alignments[alignments$dc == 6081,]
alignments6064$total = NULL
alignments6081$total = NULL
alignments6081[1:1939,-c(1:2)] = alignments6081[1:1939,-c(1:2)] + alignments6064[1:1939,-c(1:2)] 
alignments6064$total = rowSums(alignments6064[,-c(1:2)])
alignments6081$total = rowSums(alignments6081[,-c(1:2)])
alignments6081$dc = 6081

alignments[alignments$dc==6081,] = alignments6081
alignments$dc[alignments$dc == 6064] = '6064P'

# This will extend the final alignments alignmentsset into the future 500 days.
# It will simply assume that there are no changes to any alignments until
# some actually get recorded.
alignments = split(alignments, alignments$dc)
alignments = lapply(alignments, function(i) {
  n = 500
  add = do.call(rbind, replicate(n, i[nrow(i),], simplify = F))
  add$date = seq.Date(from = max(i$date)+1, length.out = n, by = 1)
  i = rbind(i,add)
  return(i)
})

alignments = do.call(rbind, alignments)


#########################
### Main Program Body ###
#########################
print("Preamble complete, beginning main program: data reading")
### Data Read in and Munge Section ###

data = readInFormat1()
data=data[data$dc==6064|data$dc==6080|data$dc==7072|data$dc==7087|data$dc==6601
          |data$dc==7088|data$dc==6081|data$dc==6094|data$dc=='6064P',]

# A separate model will be fit for each DC-Channel combination so
# here we are splitting up the data set by DC and channel.

data = split(data, interaction(data$dc, data$channel, drop = T))

# 6064 is no longer active so we're just removing that data here

data = data[names(data) %in% c('6064.PBYL','6064.SSTK') == 0]
names = names(data)

# This bit is just feature generation. This set of features works well but
# could certainly be improved/streamlined with some work

data = lapply(seq_along(data), function(i){
  data[[i]]= data[[i]][order(data[[i]]$date),]
  
  # Removing some outliers. Should be careful here and maybe check every 
  # once in a while to make sure new (valid) data points haven't been 
  # removed by these rules
  
  data[[i]]$volume[data[[i]]$volume>40000 & data[[i]]$dc == 7088 & data[[i]]$channel == 'PBYL'] = NA
  data[[i]]$volume[data[[i]]$volume>150000 & data[[i]]$dc == 6081 & data[[i]]$channel == 'SSTK'] = NA
  data[[i]]$volume[data[[i]]$volume<25000 & data[[i]]$dc == 7088 & data[[i]]$channel == 'SSTK'] = NA
  data[[i]]$volume[data[[i]]$volume<20000 & data[[i]]$dc == 6094 & data[[i]]$channel == 'SSTK'] = NA
  data[[i]]$volume[data[[i]]$volume<20000 & data[[i]]$dc == 7087 & data[[i]]$channel == 'SSTK'] = NA
  data[[i]]$volume[data[[i]]$volume == 0] = NA

